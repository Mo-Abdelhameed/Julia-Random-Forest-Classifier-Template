{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES.\n",
    "using Suppressor\n",
    "@suppress begin\n",
    "    using DataFrames, CSV, Random, Statistics, Serialization, LazyJSON, StatsBase, DecisionTree, ScientificTypes, MLJ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES \n",
    "ROOT_DIR = dirname(pwd())\n",
    "MODEL_INPUTS_OUTPUTS = joinpath(ROOT_DIR, \"model_inputs_outputs\")\n",
    "INPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"inputs\")\n",
    "INPUT_SCHEMA_DIR = joinpath(INPUT_DIR, \"schema\")\n",
    "DATA_DIR = joinpath(INPUT_DIR, \"data\")\n",
    "OUTPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"outputs\")\n",
    "TRAIN_DIR = joinpath(DATA_DIR, \"training\")\n",
    "TEST_DIR = joinpath(DATA_DIR, \"testing\")\n",
    "MODEL_PATH = joinpath(MODEL_INPUTS_OUTPUTS, \"model\")\n",
    "MODEL_ARTIFACTS_PATH = joinpath(MODEL_PATH, \"artifacts\")\n",
    "OHE_ENCODER_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"ohe.jld2\")\n",
    "PREDICTOR_DIR_PATH = joinpath(MODEL_ARTIFACTS_PATH, \"predictor\")\n",
    "PREDICTOR_FILE_PATH = joinpath(PREDICTOR_DIR_PATH, \"predictor.ser\")\n",
    "IMPUTATION_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"imputation.ser\")\n",
    "TOP_CATEGORIES = joinpath(MODEL_ARTIFACTS_PATH, \"top_categories.ser\")\n",
    "PREDICTIONS_DIR = joinpath(OUTPUT_DIR, \"predictions\")\n",
    "PREDICTIONS_FILE = joinpath(PREDICTIONS_DIR, \"predictions.csv\")\n",
    "TARGET_LEVELS = joinpath(MODEL_ARTIFACTS_PATH, \"target_levels.ser\")\n",
    "\n",
    "\n",
    "\n",
    "if !isdir(MODEL_ARTIFACTS_PATH)\n",
    "    mkdir(MODEL_ARTIFACTS_PATH)\n",
    "end\n",
    "if !isdir(PREDICTOR_DIR_PATH)\n",
    "    mkdir(PREDICTOR_DIR_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element LazyJSON.Array{Nothing, String}:\n",
       " \"acc\"\n",
       " \"good\"\n",
       " \"unacc\"\n",
       " \"vgood\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a schema from a JSON file and extracting features\n",
    "file_name = first(filter(x -> endswith(x, \"json\"), readdir(INPUT_SCHEMA_DIR)))\n",
    "schema_path = joinpath(INPUT_SCHEMA_DIR, file_name)\n",
    "schema_string = read(schema_path, String)  # Read file content as a string\n",
    "schema = LazyJSON.parse(schema_string)\n",
    "features = schema[\"features\"]\n",
    "\n",
    "# Identifying numeric, categorical, and nullable features\n",
    "numeric_features = String[]\n",
    "categorical_features = String[]\n",
    "nullable_features = String[]\n",
    "\n",
    "for f in features\n",
    "    if f[\"dataType\"] == \"CATEGORICAL\"\n",
    "        push!(categorical_features, f[\"name\"])\n",
    "    else\n",
    "        push!(numeric_features, f[\"name\"])\n",
    "    end\n",
    "    if f[\"nullable\"]\n",
    "        push!(nullable_features, f[\"name\"])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Extracting ID and target features\n",
    "id_feature = schema[\"id\"][\"name\"]\n",
    "target_feature = schema[\"target\"][\"name\"]\n",
    "target_classes = schema[\"target\"][\"classes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>346 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>buying</th><th>maint</th><th>doors</th><th>persons</th><th>lug_boot</th><th>safety</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th></tr></thead><tbody><tr><th>1</th><td>598</td><td>high</td><td>high</td><td>4</td><td>2</td><td>med</td><td>med</td></tr><tr><th>2</th><td>1674</td><td>low</td><td>low</td><td>4</td><td>2</td><td>small</td><td>low</td></tr><tr><th>3</th><td>860</td><td>high</td><td>low</td><td>5more</td><td>more</td><td>med</td><td>high</td></tr><tr><th>4</th><td>432</td><td>high</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>low</td></tr><tr><th>5</th><td>1036</td><td>med</td><td>high</td><td>4</td><td>4</td><td>small</td><td>med</td></tr><tr><th>6</th><td>793</td><td>high</td><td>low</td><td>3</td><td>4</td><td>small</td><td>med</td></tr><tr><th>7</th><td>465</td><td>high</td><td>vhigh</td><td>3</td><td>2</td><td>big</td><td>low</td></tr><tr><th>8</th><td>50</td><td>vhigh</td><td>vhigh</td><td>3</td><td>more</td><td>med</td><td>high</td></tr><tr><th>9</th><td>131</td><td>vhigh</td><td>high</td><td>2</td><td>more</td><td>med</td><td>high</td></tr><tr><th>10</th><td>109</td><td>vhigh</td><td>high</td><td>2</td><td>2</td><td>small</td><td>med</td></tr><tr><th>11</th><td>1510</td><td>low</td><td>high</td><td>5more</td><td>more</td><td>big</td><td>med</td></tr><tr><th>12</th><td>6</td><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>low</td></tr><tr><th>13</th><td>913</td><td>med</td><td>vhigh</td><td>3</td><td>more</td><td>med</td><td>med</td></tr><tr><th>14</th><td>359</td><td>vhigh</td><td>low</td><td>3</td><td>2</td><td>big</td><td>high</td></tr><tr><th>15</th><td>1592</td><td>low</td><td>med</td><td>4</td><td>more</td><td>big</td><td>high</td></tr><tr><th>16</th><td>872</td><td>med</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>high</td></tr><tr><th>17</th><td>1165</td><td>med</td><td>med</td><td>5more</td><td>2</td><td>med</td><td>med</td></tr><tr><th>18</th><td>1284</td><td>med</td><td>low</td><td>5more</td><td>4</td><td>big</td><td>low</td></tr><tr><th>19</th><td>1067</td><td>med</td><td>high</td><td>5more</td><td>4</td><td>med</td><td>high</td></tr><tr><th>20</th><td>1372</td><td>low</td><td>vhigh</td><td>4</td><td>more</td><td>med</td><td>med</td></tr><tr><th>21</th><td>921</td><td>med</td><td>vhigh</td><td>4</td><td>2</td><td>med</td><td>low</td></tr><tr><th>22</th><td>579</td><td>high</td><td>high</td><td>3</td><td>4</td><td>med</td><td>low</td></tr><tr><th>23</th><td>1376</td><td>low</td><td>vhigh</td><td>4</td><td>more</td><td>big</td><td>high</td></tr><tr><th>24</th><td>1003</td><td>med</td><td>high</td><td>3</td><td>2</td><td>med</td><td>med</td></tr><tr><th>25</th><td>732</td><td>high</td><td>med</td><td>5more</td><td>2</td><td>med</td><td>low</td></tr><tr><th>26</th><td>174</td><td>vhigh</td><td>high</td><td>4</td><td>4</td><td>med</td><td>low</td></tr><tr><th>27</th><td>1598</td><td>low</td><td>med</td><td>5more</td><td>2</td><td>med</td><td>high</td></tr><tr><th>28</th><td>1623</td><td>low</td><td>low</td><td>2</td><td>2</td><td>med</td><td>low</td></tr><tr><th>29</th><td>852</td><td>high</td><td>low</td><td>5more</td><td>4</td><td>big</td><td>low</td></tr><tr><th>30</th><td>1244</td><td>med</td><td>low</td><td>4</td><td>2</td><td>small</td><td>high</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& id & buying & maint & doors & persons & lug\\_boot & safety\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String7 & String7 & String7 & String7 & String7 & String7\\\\\n",
       "\t\\hline\n",
       "\t1 & 598 & high & high & 4 & 2 & med & med \\\\\n",
       "\t2 & 1674 & low & low & 4 & 2 & small & low \\\\\n",
       "\t3 & 860 & high & low & 5more & more & med & high \\\\\n",
       "\t4 & 432 & high & vhigh & 2 & 2 & small & low \\\\\n",
       "\t5 & 1036 & med & high & 4 & 4 & small & med \\\\\n",
       "\t6 & 793 & high & low & 3 & 4 & small & med \\\\\n",
       "\t7 & 465 & high & vhigh & 3 & 2 & big & low \\\\\n",
       "\t8 & 50 & vhigh & vhigh & 3 & more & med & high \\\\\n",
       "\t9 & 131 & vhigh & high & 2 & more & med & high \\\\\n",
       "\t10 & 109 & vhigh & high & 2 & 2 & small & med \\\\\n",
       "\t11 & 1510 & low & high & 5more & more & big & med \\\\\n",
       "\t12 & 6 & vhigh & vhigh & 2 & 2 & big & low \\\\\n",
       "\t13 & 913 & med & vhigh & 3 & more & med & med \\\\\n",
       "\t14 & 359 & vhigh & low & 3 & 2 & big & high \\\\\n",
       "\t15 & 1592 & low & med & 4 & more & big & high \\\\\n",
       "\t16 & 872 & med & vhigh & 2 & 2 & big & high \\\\\n",
       "\t17 & 1165 & med & med & 5more & 2 & med & med \\\\\n",
       "\t18 & 1284 & med & low & 5more & 4 & big & low \\\\\n",
       "\t19 & 1067 & med & high & 5more & 4 & med & high \\\\\n",
       "\t20 & 1372 & low & vhigh & 4 & more & med & med \\\\\n",
       "\t21 & 921 & med & vhigh & 4 & 2 & med & low \\\\\n",
       "\t22 & 579 & high & high & 3 & 4 & med & low \\\\\n",
       "\t23 & 1376 & low & vhigh & 4 & more & big & high \\\\\n",
       "\t24 & 1003 & med & high & 3 & 2 & med & med \\\\\n",
       "\t25 & 732 & high & med & 5more & 2 & med & low \\\\\n",
       "\t26 & 174 & vhigh & high & 4 & 4 & med & low \\\\\n",
       "\t27 & 1598 & low & med & 5more & 2 & med & high \\\\\n",
       "\t28 & 1623 & low & low & 2 & 2 & med & low \\\\\n",
       "\t29 & 852 & high & low & 5more & 4 & big & low \\\\\n",
       "\t30 & 1244 & med & low & 4 & 2 & small & high \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m346×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m id    \u001b[0m\u001b[1m buying  \u001b[0m\u001b[1m maint   \u001b[0m\u001b[1m doors   \u001b[0m\u001b[1m persons \u001b[0m\u001b[1m lug_boot \u001b[0m\u001b[1m safety  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7  \u001b[0m\u001b[90m String7 \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────\n",
       "   1 │   598  high     high     4        2        med       med\n",
       "   2 │  1674  low      low      4        2        small     low\n",
       "   3 │   860  high     low      5more    more     med       high\n",
       "   4 │   432  high     vhigh    2        2        small     low\n",
       "   5 │  1036  med      high     4        4        small     med\n",
       "   6 │   793  high     low      3        4        small     med\n",
       "   7 │   465  high     vhigh    3        2        big       low\n",
       "   8 │    50  vhigh    vhigh    3        more     med       high\n",
       "   9 │   131  vhigh    high     2        more     med       high\n",
       "  10 │   109  vhigh    high     2        2        small     med\n",
       "  11 │  1510  low      high     5more    more     big       med\n",
       "  ⋮  │   ⋮       ⋮        ⋮        ⋮        ⋮        ⋮         ⋮\n",
       " 337 │   781  high     low      2        more     big       med\n",
       " 338 │   390  vhigh    low      4        4        med       low\n",
       " 339 │  1450  low      high     3        more     small     med\n",
       " 340 │   306  vhigh    med      5more    4        small     low\n",
       " 341 │  1608  low      med      5more    4        big       low\n",
       " 342 │   735  high     med      5more    2        big       low\n",
       " 343 │    73  vhigh    vhigh    4        more     small     med\n",
       " 344 │  1350  low      vhigh    4        2        small     low\n",
       " 345 │  1015  med      high     3        4        big       med\n",
       " 346 │   972  med      high     2        2        small     low\n",
       "\u001b[36m                                                    325 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = filter(x -> occursin(\".csv\", x), readdir(TEST_DIR))[1]\n",
    "file_path = joinpath(TEST_DIR, file_name)\n",
    "df = DataFrame(CSV.File(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Note that when we work with testing data, we have to impute using the same values learned during training. This is to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>346 rows × 6 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>buying</th><th>maint</th><th>doors</th><th>persons</th><th>lug_boot</th><th>safety</th></tr><tr><th></th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th><th title=\"String7\">String7</th></tr></thead><tbody><tr><th>1</th><td>high</td><td>high</td><td>4</td><td>2</td><td>med</td><td>med</td></tr><tr><th>2</th><td>low</td><td>low</td><td>4</td><td>2</td><td>small</td><td>low</td></tr><tr><th>3</th><td>high</td><td>low</td><td>5more</td><td>more</td><td>med</td><td>high</td></tr><tr><th>4</th><td>high</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>low</td></tr><tr><th>5</th><td>med</td><td>high</td><td>4</td><td>4</td><td>small</td><td>med</td></tr><tr><th>6</th><td>high</td><td>low</td><td>3</td><td>4</td><td>small</td><td>med</td></tr><tr><th>7</th><td>high</td><td>vhigh</td><td>3</td><td>2</td><td>big</td><td>low</td></tr><tr><th>8</th><td>vhigh</td><td>vhigh</td><td>3</td><td>more</td><td>med</td><td>high</td></tr><tr><th>9</th><td>vhigh</td><td>high</td><td>2</td><td>more</td><td>med</td><td>high</td></tr><tr><th>10</th><td>vhigh</td><td>high</td><td>2</td><td>2</td><td>small</td><td>med</td></tr><tr><th>11</th><td>low</td><td>high</td><td>5more</td><td>more</td><td>big</td><td>med</td></tr><tr><th>12</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>low</td></tr><tr><th>13</th><td>med</td><td>vhigh</td><td>3</td><td>more</td><td>med</td><td>med</td></tr><tr><th>14</th><td>vhigh</td><td>low</td><td>3</td><td>2</td><td>big</td><td>high</td></tr><tr><th>15</th><td>low</td><td>med</td><td>4</td><td>more</td><td>big</td><td>high</td></tr><tr><th>16</th><td>med</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>high</td></tr><tr><th>17</th><td>med</td><td>med</td><td>5more</td><td>2</td><td>med</td><td>med</td></tr><tr><th>18</th><td>med</td><td>low</td><td>5more</td><td>4</td><td>big</td><td>low</td></tr><tr><th>19</th><td>med</td><td>high</td><td>5more</td><td>4</td><td>med</td><td>high</td></tr><tr><th>20</th><td>low</td><td>vhigh</td><td>4</td><td>more</td><td>med</td><td>med</td></tr><tr><th>21</th><td>med</td><td>vhigh</td><td>4</td><td>2</td><td>med</td><td>low</td></tr><tr><th>22</th><td>high</td><td>high</td><td>3</td><td>4</td><td>med</td><td>low</td></tr><tr><th>23</th><td>low</td><td>vhigh</td><td>4</td><td>more</td><td>big</td><td>high</td></tr><tr><th>24</th><td>med</td><td>high</td><td>3</td><td>2</td><td>med</td><td>med</td></tr><tr><th>25</th><td>high</td><td>med</td><td>5more</td><td>2</td><td>med</td><td>low</td></tr><tr><th>26</th><td>vhigh</td><td>high</td><td>4</td><td>4</td><td>med</td><td>low</td></tr><tr><th>27</th><td>low</td><td>med</td><td>5more</td><td>2</td><td>med</td><td>high</td></tr><tr><th>28</th><td>low</td><td>low</td><td>2</td><td>2</td><td>med</td><td>low</td></tr><tr><th>29</th><td>high</td><td>low</td><td>5more</td><td>4</td><td>big</td><td>low</td></tr><tr><th>30</th><td>med</td><td>low</td><td>4</td><td>2</td><td>small</td><td>high</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& buying & maint & doors & persons & lug\\_boot & safety\\\\\n",
       "\t\\hline\n",
       "\t& String7 & String7 & String7 & String7 & String7 & String7\\\\\n",
       "\t\\hline\n",
       "\t1 & high & high & 4 & 2 & med & med \\\\\n",
       "\t2 & low & low & 4 & 2 & small & low \\\\\n",
       "\t3 & high & low & 5more & more & med & high \\\\\n",
       "\t4 & high & vhigh & 2 & 2 & small & low \\\\\n",
       "\t5 & med & high & 4 & 4 & small & med \\\\\n",
       "\t6 & high & low & 3 & 4 & small & med \\\\\n",
       "\t7 & high & vhigh & 3 & 2 & big & low \\\\\n",
       "\t8 & vhigh & vhigh & 3 & more & med & high \\\\\n",
       "\t9 & vhigh & high & 2 & more & med & high \\\\\n",
       "\t10 & vhigh & high & 2 & 2 & small & med \\\\\n",
       "\t11 & low & high & 5more & more & big & med \\\\\n",
       "\t12 & vhigh & vhigh & 2 & 2 & big & low \\\\\n",
       "\t13 & med & vhigh & 3 & more & med & med \\\\\n",
       "\t14 & vhigh & low & 3 & 2 & big & high \\\\\n",
       "\t15 & low & med & 4 & more & big & high \\\\\n",
       "\t16 & med & vhigh & 2 & 2 & big & high \\\\\n",
       "\t17 & med & med & 5more & 2 & med & med \\\\\n",
       "\t18 & med & low & 5more & 4 & big & low \\\\\n",
       "\t19 & med & high & 5more & 4 & med & high \\\\\n",
       "\t20 & low & vhigh & 4 & more & med & med \\\\\n",
       "\t21 & med & vhigh & 4 & 2 & med & low \\\\\n",
       "\t22 & high & high & 3 & 4 & med & low \\\\\n",
       "\t23 & low & vhigh & 4 & more & big & high \\\\\n",
       "\t24 & med & high & 3 & 2 & med & med \\\\\n",
       "\t25 & high & med & 5more & 2 & med & low \\\\\n",
       "\t26 & vhigh & high & 4 & 4 & med & low \\\\\n",
       "\t27 & low & med & 5more & 2 & med & high \\\\\n",
       "\t28 & low & low & 2 & 2 & med & low \\\\\n",
       "\t29 & high & low & 5more & 4 & big & low \\\\\n",
       "\t30 & med & low & 4 & 2 & small & high \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m346×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m buying  \u001b[0m\u001b[1m maint   \u001b[0m\u001b[1m doors   \u001b[0m\u001b[1m persons \u001b[0m\u001b[1m lug_boot \u001b[0m\u001b[1m safety  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String7 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String7  \u001b[0m\u001b[90m String7 \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────\n",
       "   1 │ high     high     4        2        med       med\n",
       "   2 │ low      low      4        2        small     low\n",
       "   3 │ high     low      5more    more     med       high\n",
       "   4 │ high     vhigh    2        2        small     low\n",
       "   5 │ med      high     4        4        small     med\n",
       "   6 │ high     low      3        4        small     med\n",
       "   7 │ high     vhigh    3        2        big       low\n",
       "   8 │ vhigh    vhigh    3        more     med       high\n",
       "   9 │ vhigh    high     2        more     med       high\n",
       "  10 │ vhigh    high     2        2        small     med\n",
       "  11 │ low      high     5more    more     big       med\n",
       "  ⋮  │    ⋮        ⋮        ⋮        ⋮        ⋮         ⋮\n",
       " 337 │ high     low      2        more     big       med\n",
       " 338 │ vhigh    low      4        4        med       low\n",
       " 339 │ low      high     3        more     small     med\n",
       " 340 │ vhigh    med      5more    4        small     low\n",
       " 341 │ low      med      5more    4        big       low\n",
       " 342 │ high     med      5more    2        big       low\n",
       " 343 │ vhigh    vhigh    4        more     small     med\n",
       " 344 │ low      vhigh    4        2        small     low\n",
       " 345 │ med      high     3        4        big       med\n",
       " 346 │ med      high     2        2        small     low\n",
       "\u001b[36m                                             325 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_values = open(deserialize, IMPUTATION_FILE)\n",
    "for column in nullable_features\n",
    "    df[!, Symbol(column)] .= coalesce.(df[!, Symbol(column)], get(imputation_values, string(column), missing))\n",
    "end\n",
    "\n",
    "# Saving the id column in a different variable\n",
    "ids = df[!, Symbol(id_feature)]\n",
    "\n",
    "# Dropping the id from the DataFrame\n",
    "select!(df, Not([Symbol(id_feature)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "We encode the data using the same encoder that we saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_top_categories = open(deserialize, TOP_CATEGORIES)\n",
    "\n",
    "# Function to one-hot encode only the top 3 categories\n",
    "function one_hot_top_categories!(df, top_categories)\n",
    "    for (feature, top_cats) in top_categories\n",
    "        if length(top_cats) == 2  # Handle the binary case\n",
    "            # Assuming the first category in top_cats is treated as 'true'\n",
    "            new_col_name = \"$(feature)_binary\"\n",
    "            df[!, new_col_name] = df[!, feature] .== top_cats[1]\n",
    "        else  # Handle the general case\n",
    "            for cat in top_cats\n",
    "                new_col_name = \"$(feature)_$(cat)\"\n",
    "                df[!, new_col_name] = df[!, feature] .== cat\n",
    "            end\n",
    "        end\n",
    "        select!(df, Not(Symbol(feature)))  # Drop the original feature column\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "one_hot_top_categories!(df, loaded_top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions & Creating Predictions DataFrame\n",
    "Using the model saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/moo/Desktop/Upwork/rt-ML/Regression/Julia/Julia-Random-Forest-Classifier-Template/model_inputs_outputs/outputs/predictions/predictions.csv\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function convert_to_string(item)\n",
    "    if typeof(item) <: Number\n",
    "        return string(item)\n",
    "    else\n",
    "        # Strip surrounding quotes if the item is a string\n",
    "        return strip(String(item), '\"')\n",
    "    end\n",
    "end\n",
    "\n",
    "model = open(deserialize, PREDICTOR_FILE_PATH)\n",
    "predictions = apply_forest_proba(model, Matrix(df), [convert_to_string(item) for item in target_classes])\n",
    "predictions = DataFrame(predictions, Symbol.(target_classes))\n",
    "insertcols!(predictions, 1, id_feature => ids)\n",
    "CSV.write(PREDICTIONS_FILE, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
