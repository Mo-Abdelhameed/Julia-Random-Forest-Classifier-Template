{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES.\n",
    "using Suppressor\n",
    "@suppress begin\n",
    "    using DataFrames, CSV, Random, Statistics, Serialization, LazyJSON, StatsBase, DecisionTree, ScientificTypes, MLJ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES \n",
    "ROOT_DIR = dirname(pwd())\n",
    "MODEL_INPUTS_OUTPUTS = joinpath(ROOT_DIR, \"model_inputs_outputs\")\n",
    "INPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"inputs\")\n",
    "INPUT_SCHEMA_DIR = joinpath(INPUT_DIR, \"schema\")\n",
    "DATA_DIR = joinpath(INPUT_DIR, \"data\")\n",
    "OUTPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"outputs\")\n",
    "TRAIN_DIR = joinpath(DATA_DIR, \"training\")\n",
    "TEST_DIR = joinpath(DATA_DIR, \"testing\")\n",
    "MODEL_PATH = joinpath(MODEL_INPUTS_OUTPUTS, \"model\")\n",
    "MODEL_ARTIFACTS_PATH = joinpath(MODEL_PATH, \"artifacts\")\n",
    "OHE_ENCODER_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"ohe.jld2\")\n",
    "PREDICTOR_DIR_PATH = joinpath(MODEL_ARTIFACTS_PATH, \"predictor\")\n",
    "PREDICTOR_FILE_PATH = joinpath(PREDICTOR_DIR_PATH, \"predictor.ser\")\n",
    "IMPUTATION_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"imputation.ser\")\n",
    "TOP_CATEGORIES = joinpath(MODEL_ARTIFACTS_PATH, \"top_categories.ser\")\n",
    "PREDICTIONS_DIR = joinpath(OUTPUT_DIR, \"predictions\")\n",
    "PREDICTIONS_FILE = joinpath(PREDICTIONS_DIR, \"predictions.csv\")\n",
    "TARGET_LEVELS = joinpath(MODEL_ARTIFACTS_PATH, \"target_levels.ser\")\n",
    "\n",
    "\n",
    "\n",
    "if !isdir(MODEL_ARTIFACTS_PATH)\n",
    "    mkdir(MODEL_ARTIFACTS_PATH)\n",
    "end\n",
    "if !isdir(PREDICTOR_DIR_PATH)\n",
    "    mkdir(PREDICTOR_DIR_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19-element LazyJSON.Array{Nothing, String}:\n",
       " \" 2-4-d-injury\"\n",
       " \" alternarialeaf-spot\"\n",
       " \" anthracnose\"\n",
       " \" bacterial-blight\"\n",
       " \" bacterial-pustule\"\n",
       " \" brown-spot\"\n",
       " \" brown-stem-rot\"\n",
       " \" charcoal-rot\"\n",
       " \" cyst-nematode\"\n",
       " \" diaporthe-pod-&-stem-blight\"\n",
       " \" diaporthe-stem-canker\"\n",
       " \" downy-mildew\"\n",
       " \" frog-eye-leaf-spot\"\n",
       " \" herbicide-injury\"\n",
       " \" phyllosticta-leaf-spot\"\n",
       " \" phytophthora-rot\"\n",
       " \" powdery-mildew\"\n",
       " \" purple-seed-stain\"\n",
       " \" rhizoctonia-root-rot\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a schema from a JSON file and extracting features\n",
    "file_name = first(filter(x -> endswith(x, \"json\"), readdir(INPUT_SCHEMA_DIR)))\n",
    "schema_path = joinpath(INPUT_SCHEMA_DIR, file_name)\n",
    "schema_string = read(schema_path, String)  # Read file content as a string\n",
    "schema = LazyJSON.parse(schema_string)\n",
    "features = schema[\"features\"]\n",
    "\n",
    "# Identifying numeric, categorical, and nullable features\n",
    "numeric_features = String[]\n",
    "categorical_features = String[]\n",
    "nullable_features = String[]\n",
    "\n",
    "for f in features\n",
    "    if f[\"dataType\"] == \"CATEGORICAL\"\n",
    "        push!(categorical_features, f[\"name\"])\n",
    "    else\n",
    "        push!(numeric_features, f[\"name\"])\n",
    "    end\n",
    "    if f[\"nullable\"]\n",
    "        push!(nullable_features, f[\"name\"])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Extracting ID and target features\n",
    "id_feature = schema[\"id\"][\"name\"]\n",
    "target_feature = schema[\"target\"][\"name\"]\n",
    "target_classes = schema[\"target\"][\"classes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>137 rows Ã— 36 columns (omitted printing of 29 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>date</th><th>plant-stand</th><th>precip</th><th>temp</th><th>hail</th><th>crop-hist</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"Union{Missing, String7}\">String7?</th><th title=\"Union{Missing, String31}\">String31?</th></tr></thead><tbody><tr><th>1</th><td>178</td><td>september</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>2</th><td>603</td><td>august</td><td> normal</td><td> norm</td><td> norm</td><td> no</td><td> same-lst-sev-yrs</td></tr><tr><th>3</th><td>341</td><td>july</td><td> lt-normal</td><td> norm</td><td> norm</td><td><em>missing</em></td><td> same-lst-two-yrs</td></tr><tr><th>4</th><td>599</td><td>august</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>5</th><td>536</td><td>july</td><td> normal</td><td> lt-norm</td><td> norm</td><td> no</td><td> same-lst-two-yrs</td></tr><tr><th>6</th><td>615</td><td>july</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>7</th><td>478</td><td>july</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td></tr><tr><th>8</th><td>620</td><td>september</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-sev-yrs</td></tr><tr><th>9</th><td>16</td><td>october</td><td> normal</td><td> lt-norm</td><td> gt-norm</td><td> no</td><td> diff-lst-year</td></tr><tr><th>10</th><td>224</td><td>september</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> diff-lst-year</td></tr><tr><th>11</th><td>556</td><td>october</td><td> lt-normal</td><td> norm</td><td> gt-norm</td><td> no</td><td> same-lst-yr</td></tr><tr><th>12</th><td>299</td><td>july</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td> same-lst-two-yrs</td></tr><tr><th>13</th><td>378</td><td>august</td><td> lt-normal</td><td> norm</td><td> norm</td><td><em>missing</em></td><td> same-lst-yr</td></tr><tr><th>14</th><td>610</td><td>august</td><td> normal</td><td> gt-norm</td><td> gt-norm</td><td> no</td><td> same-lst-yr</td></tr><tr><th>15</th><td>361</td><td>may</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td><em>missing</em></td><td> same-lst-sev-yrs</td></tr><tr><th>16</th><td>286</td><td>august</td><td> normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>17</th><td>335</td><td>april</td><td> lt-normal</td><td> gt-norm</td><td> lt-norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>18</th><td>104</td><td>may</td><td> normal</td><td> gt-norm</td><td> lt-norm</td><td> no</td><td> diff-lst-year</td></tr><tr><th>19</th><td>119</td><td>june</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td></tr><tr><th>20</th><td>597</td><td>august</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-two-yrs</td></tr><tr><th>21</th><td>522</td><td>july</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> no</td><td> same-lst-yr</td></tr><tr><th>22</th><td>97</td><td>october</td><td> lt-normal</td><td> lt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>23</th><td>520</td><td>september</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td></tr><tr><th>24</th><td>60</td><td>june</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td><em>missing</em></td><td> same-lst-sev-yrs</td></tr><tr><th>25</th><td>221</td><td>august</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td></tr><tr><th>26</th><td>230</td><td>september</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-sev-yrs</td></tr><tr><th>27</th><td>128</td><td>may</td><td> lt-normal</td><td> norm</td><td> norm</td><td> no</td><td> same-lst-two-yrs</td></tr><tr><th>28</th><td>563</td><td>october</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td></tr><tr><th>29</th><td>124</td><td>may</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-two-yrs</td></tr><tr><th>30</th><td>238</td><td>september</td><td> normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-two-yrs</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& id & date & plant-stand & precip & temp & hail & crop-hist & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String15 & String15? & String15? & String15? & String7? & String31? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 178 & september &  normal &  gt-norm &  norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t2 & 603 & august &  normal &  norm &  norm &  no &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t3 & 341 & july &  lt-normal &  norm &  norm & \\emph{missing} &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t4 & 599 & august &  normal &  gt-norm &  norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t5 & 536 & july &  normal &  lt-norm &  norm &  no &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t6 & 615 & july &  normal &  gt-norm &  norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t7 & 478 & july &  lt-normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t8 & 620 & september &  lt-normal &  gt-norm &  gt-norm &  yes &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t9 & 16 & october &  normal &  lt-norm &  gt-norm &  no &  diff-lst-year & $\\dots$ \\\\\n",
       "\t10 & 224 & september &  lt-normal &  gt-norm &  norm &  yes &  diff-lst-year & $\\dots$ \\\\\n",
       "\t11 & 556 & october &  lt-normal &  norm &  gt-norm &  no &  same-lst-yr & $\\dots$ \\\\\n",
       "\t12 & 299 & july & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t13 & 378 & august &  lt-normal &  norm &  norm & \\emph{missing} &  same-lst-yr & $\\dots$ \\\\\n",
       "\t14 & 610 & august &  normal &  gt-norm &  gt-norm &  no &  same-lst-yr & $\\dots$ \\\\\n",
       "\t15 & 361 & may &  lt-normal &  gt-norm &  gt-norm & \\emph{missing} &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t16 & 286 & august &  normal &  gt-norm &  gt-norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t17 & 335 & april &  lt-normal &  gt-norm &  lt-norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t18 & 104 & may &  normal &  gt-norm &  lt-norm &  no &  diff-lst-year & $\\dots$ \\\\\n",
       "\t19 & 119 & june &  lt-normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t20 & 597 & august &  normal &  gt-norm &  norm &  yes &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t21 & 522 & july &  lt-normal &  gt-norm &  gt-norm &  no &  same-lst-yr & $\\dots$ \\\\\n",
       "\t22 & 97 & october &  lt-normal &  lt-norm &  norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t23 & 520 & september &  normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t24 & 60 & june &  lt-normal &  gt-norm &  gt-norm & \\emph{missing} &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t25 & 221 & august &  lt-normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t26 & 230 & september &  lt-normal &  gt-norm &  gt-norm &  yes &  same-lst-sev-yrs & $\\dots$ \\\\\n",
       "\t27 & 128 & may &  lt-normal &  norm &  norm &  no &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t28 & 563 & october &  normal &  gt-norm &  norm &  yes &  same-lst-yr & $\\dots$ \\\\\n",
       "\t29 & 124 & may &  normal &  gt-norm &  norm &  yes &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t30 & 238 & september &  normal &  gt-norm &  gt-norm &  yes &  same-lst-two-yrs & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m137Ã—36 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m id    \u001b[0m\u001b[1m date      \u001b[0m\u001b[1m plant-stand \u001b[0m\u001b[1m precip    \u001b[0m\u001b[1m temp      \u001b[0m\u001b[1m hail     \u001b[0m\u001b[1m crop-his\u001b[0m â‹¯\n",
       "\u001b[1m     \u001b[0mâ”‚\u001b[90m Int64 \u001b[0m\u001b[90m String15  \u001b[0m\u001b[90m String15?   \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String7? \u001b[0m\u001b[90m String31\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚   178  september   normal       gt-norm    norm       yes       same-ls â‹¯\n",
       "   2 â”‚   603  august      normal       norm       norm       no        same-ls\n",
       "   3 â”‚   341  july        lt-normal    norm       norm     \u001b[90m missing  \u001b[0m  same-ls\n",
       "   4 â”‚   599  august      normal       gt-norm    norm       yes       same-ls\n",
       "   5 â”‚   536  july        normal       lt-norm    norm       no        same-ls â‹¯\n",
       "   6 â”‚   615  july        normal       gt-norm    norm       yes       same-ls\n",
       "   7 â”‚   478  july        lt-normal    gt-norm    norm       yes       same-ls\n",
       "   8 â”‚   620  september   lt-normal    gt-norm    gt-norm    yes       same-ls\n",
       "   9 â”‚    16  october     normal       lt-norm    gt-norm    no        diff-ls â‹¯\n",
       "  10 â”‚   224  september   lt-normal    gt-norm    norm       yes       diff-ls\n",
       "  11 â”‚   556  october     lt-normal    norm       gt-norm    no        same-ls\n",
       "  â‹®  â”‚   â‹®        â‹®           â‹®           â‹®          â‹®         â‹®               â‹±\n",
       " 128 â”‚   176  july        normal       gt-norm    lt-norm    no        diff-ls\n",
       " 129 â”‚   198  september   lt-normal    gt-norm    norm       yes       same-ls â‹¯\n",
       " 130 â”‚   634  september   normal       gt-norm    norm       yes       same-ls\n",
       " 131 â”‚   418  september   lt-normal    lt-norm    norm       yes       same-ls\n",
       " 132 â”‚    55  may         lt-normal    gt-norm    norm       no        same-ls\n",
       " 133 â”‚   332  june        lt-normal    gt-norm    lt-norm    yes       same-ls â‹¯\n",
       " 134 â”‚   630  september   normal       gt-norm    gt-norm    yes       same-ls\n",
       " 135 â”‚   217  september   lt-normal    gt-norm    gt-norm    yes       same-ls\n",
       " 136 â”‚   681  april       lt-normal  \u001b[90m missing   \u001b[0m  lt-norm  \u001b[90m missing  \u001b[0m  same-ls\n",
       " 137 â”‚   195  october     lt-normal    gt-norm    gt-norm    no        diff-ls â‹¯\n",
       "\u001b[36m                                                 30 columns and 116 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = filter(x -> occursin(\".csv\", x), readdir(TEST_DIR))[1]\n",
    "file_path = joinpath(TEST_DIR, file_name)\n",
    "df = DataFrame(CSV.File(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Note that when we work with testing data, we have to impute using the same values learned during training. This is to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>137 rows Ã— 35 columns (omitted printing of 28 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>plant-stand</th><th>precip</th><th>temp</th><th>hail</th><th>crop-hist</th><th>area-damaged</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"String15\">String15</th><th title=\"String15\">String15</th><th title=\"String15\">String15</th><th title=\"String7\">String7</th><th title=\"String31\">String31</th><th title=\"String15\">String15</th></tr></thead><tbody><tr><th>1</th><td>september</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>2</th><td>august</td><td> normal</td><td> norm</td><td> norm</td><td> no</td><td> same-lst-sev-yrs</td><td> low-areas</td></tr><tr><th>3</th><td>july</td><td> lt-normal</td><td> norm</td><td> norm</td><td> yes</td><td> same-lst-two-yrs</td><td> low-areas</td></tr><tr><th>4</th><td>august</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td><td> whole-field</td></tr><tr><th>5</th><td>july</td><td> normal</td><td> lt-norm</td><td> norm</td><td> no</td><td> same-lst-two-yrs</td><td> whole-field</td></tr><tr><th>6</th><td>july</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td><td> scattered</td></tr><tr><th>7</th><td>july</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> whole-field</td></tr><tr><th>8</th><td>september</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> low-areas</td></tr><tr><th>9</th><td>october</td><td> normal</td><td> lt-norm</td><td> gt-norm</td><td> no</td><td> diff-lst-year</td><td> upper-areas</td></tr><tr><th>10</th><td>september</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> diff-lst-year</td><td> scattered</td></tr><tr><th>11</th><td>october</td><td> lt-normal</td><td> norm</td><td> gt-norm</td><td> no</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>12</th><td>july</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-two-yrs</td><td> low-areas</td></tr><tr><th>13</th><td>august</td><td> lt-normal</td><td> norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>14</th><td>august</td><td> normal</td><td> gt-norm</td><td> gt-norm</td><td> no</td><td> same-lst-yr</td><td> scattered</td></tr><tr><th>15</th><td>may</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> low-areas</td></tr><tr><th>16</th><td>august</td><td> normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-yr</td><td> whole-field</td></tr><tr><th>17</th><td>april</td><td> lt-normal</td><td> gt-norm</td><td> lt-norm</td><td> yes</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>18</th><td>may</td><td> normal</td><td> gt-norm</td><td> lt-norm</td><td> no</td><td> diff-lst-year</td><td> scattered</td></tr><tr><th>19</th><td>june</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> whole-field</td></tr><tr><th>20</th><td>august</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-two-yrs</td><td> upper-areas</td></tr><tr><th>21</th><td>july</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> no</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>22</th><td>october</td><td> lt-normal</td><td> lt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>23</th><td>september</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> whole-field</td></tr><tr><th>24</th><td>june</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> low-areas</td></tr><tr><th>25</th><td>august</td><td> lt-normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> scattered</td></tr><tr><th>26</th><td>september</td><td> lt-normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-sev-yrs</td><td> low-areas</td></tr><tr><th>27</th><td>may</td><td> lt-normal</td><td> norm</td><td> norm</td><td> no</td><td> same-lst-two-yrs</td><td> scattered</td></tr><tr><th>28</th><td>october</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-yr</td><td> low-areas</td></tr><tr><th>29</th><td>may</td><td> normal</td><td> gt-norm</td><td> norm</td><td> yes</td><td> same-lst-two-yrs</td><td> whole-field</td></tr><tr><th>30</th><td>september</td><td> normal</td><td> gt-norm</td><td> gt-norm</td><td> yes</td><td> same-lst-two-yrs</td><td> whole-field</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& date & plant-stand & precip & temp & hail & crop-hist & area-damaged & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15 & String15 & String15 & String7 & String31 & String15 & \\\\\n",
       "\t\\hline\n",
       "\t1 & september &  normal &  gt-norm &  norm &  yes &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t2 & august &  normal &  norm &  norm &  no &  same-lst-sev-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t3 & july &  lt-normal &  norm &  norm &  yes &  same-lst-two-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t4 & august &  normal &  gt-norm &  norm &  yes &  same-lst-yr &  whole-field & $\\dots$ \\\\\n",
       "\t5 & july &  normal &  lt-norm &  norm &  no &  same-lst-two-yrs &  whole-field & $\\dots$ \\\\\n",
       "\t6 & july &  normal &  gt-norm &  norm &  yes &  same-lst-yr &  scattered & $\\dots$ \\\\\n",
       "\t7 & july &  lt-normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs &  whole-field & $\\dots$ \\\\\n",
       "\t8 & september &  lt-normal &  gt-norm &  gt-norm &  yes &  same-lst-sev-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t9 & october &  normal &  lt-norm &  gt-norm &  no &  diff-lst-year &  upper-areas & $\\dots$ \\\\\n",
       "\t10 & september &  lt-normal &  gt-norm &  norm &  yes &  diff-lst-year &  scattered & $\\dots$ \\\\\n",
       "\t11 & october &  lt-normal &  norm &  gt-norm &  no &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t12 & july &  normal &  gt-norm &  norm &  yes &  same-lst-two-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t13 & august &  lt-normal &  norm &  norm &  yes &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t14 & august &  normal &  gt-norm &  gt-norm &  no &  same-lst-yr &  scattered & $\\dots$ \\\\\n",
       "\t15 & may &  lt-normal &  gt-norm &  gt-norm &  yes &  same-lst-sev-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t16 & august &  normal &  gt-norm &  gt-norm &  yes &  same-lst-yr &  whole-field & $\\dots$ \\\\\n",
       "\t17 & april &  lt-normal &  gt-norm &  lt-norm &  yes &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t18 & may &  normal &  gt-norm &  lt-norm &  no &  diff-lst-year &  scattered & $\\dots$ \\\\\n",
       "\t19 & june &  lt-normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs &  whole-field & $\\dots$ \\\\\n",
       "\t20 & august &  normal &  gt-norm &  norm &  yes &  same-lst-two-yrs &  upper-areas & $\\dots$ \\\\\n",
       "\t21 & july &  lt-normal &  gt-norm &  gt-norm &  no &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t22 & october &  lt-normal &  lt-norm &  norm &  yes &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t23 & september &  normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs &  whole-field & $\\dots$ \\\\\n",
       "\t24 & june &  lt-normal &  gt-norm &  gt-norm &  yes &  same-lst-sev-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t25 & august &  lt-normal &  gt-norm &  norm &  yes &  same-lst-sev-yrs &  scattered & $\\dots$ \\\\\n",
       "\t26 & september &  lt-normal &  gt-norm &  gt-norm &  yes &  same-lst-sev-yrs &  low-areas & $\\dots$ \\\\\n",
       "\t27 & may &  lt-normal &  norm &  norm &  no &  same-lst-two-yrs &  scattered & $\\dots$ \\\\\n",
       "\t28 & october &  normal &  gt-norm &  norm &  yes &  same-lst-yr &  low-areas & $\\dots$ \\\\\n",
       "\t29 & may &  normal &  gt-norm &  norm &  yes &  same-lst-two-yrs &  whole-field & $\\dots$ \\\\\n",
       "\t30 & september &  normal &  gt-norm &  gt-norm &  yes &  same-lst-two-yrs &  whole-field & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m137Ã—35 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m date      \u001b[0m\u001b[1m plant-stand \u001b[0m\u001b[1m precip   \u001b[0m\u001b[1m temp     \u001b[0m\u001b[1m hail    \u001b[0m\u001b[1m crop-hist         \u001b[0m\u001b[1m\u001b[0m â‹¯\n",
       "\u001b[1m     \u001b[0mâ”‚\u001b[90m String15  \u001b[0m\u001b[90m String15    \u001b[0m\u001b[90m String15 \u001b[0m\u001b[90m String15 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String31          \u001b[0m\u001b[90m\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚ september   normal       gt-norm   norm      yes      same-lst-yr       â‹¯\n",
       "   2 â”‚ august      normal       norm      norm      no       same-lst-sev-yrs\n",
       "   3 â”‚ july        lt-normal    norm      norm      yes      same-lst-two-yrs\n",
       "   4 â”‚ august      normal       gt-norm   norm      yes      same-lst-yr\n",
       "   5 â”‚ july        normal       lt-norm   norm      no       same-lst-two-yrs  â‹¯\n",
       "   6 â”‚ july        normal       gt-norm   norm      yes      same-lst-yr\n",
       "   7 â”‚ july        lt-normal    gt-norm   norm      yes      same-lst-sev-yrs\n",
       "   8 â”‚ september   lt-normal    gt-norm   gt-norm   yes      same-lst-sev-yrs\n",
       "   9 â”‚ october     normal       lt-norm   gt-norm   no       diff-lst-year     â‹¯\n",
       "  10 â”‚ september   lt-normal    gt-norm   norm      yes      diff-lst-year\n",
       "  11 â”‚ october     lt-normal    norm      gt-norm   no       same-lst-yr\n",
       "  â‹®  â”‚     â‹®           â‹®          â‹®         â‹®         â‹®             â‹®          â‹±\n",
       " 128 â”‚ july        normal       gt-norm   lt-norm   no       diff-lst-year\n",
       " 129 â”‚ september   lt-normal    gt-norm   norm      yes      same-lst-sev-yrs  â‹¯\n",
       " 130 â”‚ september   normal       gt-norm   norm      yes      same-lst-two-yrs\n",
       " 131 â”‚ september   lt-normal    lt-norm   norm      yes      same-lst-sev-yrs\n",
       " 132 â”‚ may         lt-normal    gt-norm   norm      no       same-lst-sev-yrs\n",
       " 133 â”‚ june        lt-normal    gt-norm   lt-norm   yes      same-lst-sev-yrs  â‹¯\n",
       " 134 â”‚ september   normal       gt-norm   gt-norm   yes      same-lst-yr\n",
       " 135 â”‚ september   lt-normal    gt-norm   gt-norm   yes      same-lst-sev-yrs\n",
       " 136 â”‚ april       lt-normal    gt-norm   lt-norm   yes      same-lst-yr\n",
       " 137 â”‚ october     lt-normal    gt-norm   gt-norm   no       diff-lst-year     â‹¯\n",
       "\u001b[36m                                                 29 columns and 116 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_values = open(deserialize, IMPUTATION_FILE)\n",
    "for column in nullable_features\n",
    "    df[!, Symbol(column)] .= coalesce.(df[!, Symbol(column)], get(imputation_values, string(column), missing))\n",
    "end\n",
    "\n",
    "# Saving the id column in a different variable\n",
    "ids = df[!, Symbol(id_feature)]\n",
    "\n",
    "# Dropping the id from the DataFrame\n",
    "select!(df, Not([Symbol(id_feature)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "We encode the data using the same encoder that we saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_top_categories = open(deserialize, TOP_CATEGORIES)\n",
    "\n",
    "# Function to one-hot encode only the top 3 categories\n",
    "function one_hot_top_categories!(df, top_categories)\n",
    "    for (feature, top_cats) in top_categories\n",
    "        if length(top_cats) == 2  # Handle the binary case\n",
    "            # Assuming the first category in top_cats is treated as 'true'\n",
    "            new_col_name = \"$(feature)_binary\"\n",
    "            df[!, new_col_name] = df[!, feature] .== top_cats[1]\n",
    "        else  # Handle the general case\n",
    "            for cat in top_cats\n",
    "                new_col_name = \"$(feature)_$(cat)\"\n",
    "                df[!, new_col_name] = df[!, feature] .== cat\n",
    "            end\n",
    "        end\n",
    "        select!(df, Not(Symbol(feature)))  # Drop the original feature column\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "one_hot_top_categories!(df, loaded_top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions & Creating Predictions DataFrame\n",
    "Using the model saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/moo/Desktop/Upwork/rt-ML/Regression/Julia/Julia-Random-Forest-Classifier-Template/model_inputs_outputs/outputs/predictions/predictions.csv\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_levels = open(deserialize, TARGET_LEVELS)\n",
    "model = open(deserialize, PREDICTOR_FILE_PATH)\n",
    "predictions = apply_forest_proba(model, Matrix(df), target_classes)\n",
    "predictions = DataFrame(predictions, Symbol.(target_classes))\n",
    "insertcols!(predictions, 1, id_feature => ids)\n",
    "CSV.write(PREDICTIONS_FILE, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
